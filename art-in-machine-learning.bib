% This file was created with JabRef 2.10.
% Encoding: UTF-8


@Article{hochreiter1997long,
  Title                    = {Long short-term memory},
  Author                   = {Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  Journal                  = {Neural computation},
  Year                     = {1997},
  Number                   = {8},
  Pages                    = {1735--1780},
  Volume                   = {9},

  File                     = {:/home/moose/machines-dream-paper/lstm-ContentServer.pdf:PDF},
  Publisher                = {MIT Press},
  Url                      = {http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=6795963}
}

@Book{Mitchell97,
  Title                    = {Machine learning},
  Author                   = {Tom M. Mitchell},
  Publisher                = {McGraw-Hill},
  Year                     = {1997},
  Series                   = {McGraw Hill series in computer science},

  Bibsource                = {DBLP, http://dblp.uni-trier.de},
  Comment                  = {ISBN: 0-07-042807-7},
  File                     = {:/var/www/write-math/papers/machine-learning-tom-mitchell.pdf:PDF},
  ISBN                     = {978-0-07-042807-2},
  Owner                    = {Martin Thoma},
  Pages                    = {I-XVII, 1-414},
  Timestamp                = {2014.06.17}
}

@Misc{googleDeepDream,
  Title                    = {DeepDream - a code example for visualizing Neural Networks},

  Author                   = {Alexander Mordvintsev AND Christopher Olah AND Mike Tyka},
  HowPublished             = {googleresearch.blogspot.co.uk},
  Month                    = jul,
  Year                     = {2015},

  Comment                  = {Caffe based code on https://github.com/google/deepdream},
  Owner                    = {moose},
  Timestamp                = {2015.12.05},
  Url                      = {http://googleresearch.blogspot.co.uk/2015/07/deepdream-code-example-for-visualizing.html}
}

@Misc{inceptionism2015,
  Title                    = {Inceptionism: Going Deeper into Neural Networks},

  Author                   = {Alexander Mordvintsev AND Christopher Olah AND Mike Tyka},
  HowPublished             = {googleresearch.blogspot.co.uk},
  Month                    = jun,
  Year                     = {2015},

  Owner                    = {moose},
  Timestamp                = {2015.12.05},
  Url                      = {http://googleresearch.blogspot.de/2015/06/inceptionism-going-deeper-into-neural.html}
}

@Article{nayebigruv,
  Title                    = {GRUV: Algorithmic Music Generation using Recurrent Neural Networks},
  Author                   = {Nayebi, Aran and Vitelli, Matt},

  File                     = {:/home/moose/machines-dream-paper/NayebiAran.pdf:PDF},
  Review                   = {Authors use Recurrent Neural Networks (LTSMs to be exact) together with GRU (Gated Recurrent Units) to build a network which can be trained to generate music.
Instead of taking notes / MIDI files, they took raw audio waveforms as input. Those audio waveforms are feature vectors given for time steps $0, 1, \dots, t-1, t$.
The network is given those feature vectors $X_1, \dots, X_t$ and has to predict the following feature vector $X_{t+1}$. This means it continues the music.
As the input is continous, the problem was modeled as a regression task.
Discrete Fourier Transformation (DFT) was used on chunks of length N of the music to obtain features in the domain of the frequency.},
  Url                      = {http://cs224d.stanford.edu/reports/NayebiAran.pdf}
}

@Article{vinyals2015neural,
  Title                    = {A neural conversational model},
  Author                   = {Vinyals, Oriol and Le, Quoc},
  Journal                  = {arXiv preprint arXiv:1506.05869},
  Year                     = {2015},

  Month                    = jul,

  File                     = {:/home/moose/machines-dream-paper/1506.05869v2.pdf:PDF},
  Url                      = {http://arxiv.org/abs/1506.05869v2}
}

